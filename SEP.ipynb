{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SEP Forecasting \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Current physics based models of SEPs are unable to execute sufficiently fast in order to\n",
    "provide actionable information towards forecasting such disturbances, which can impact\n",
    "Earth within tens of minutes of the onset of an eruptive event. This is compounded by\n",
    "the intrinsic latency of certain key observations, which are used to define the initial\n",
    "conditions of these models. Instead, there is a reliance on statistical models to provide\n",
    "forecast probabilities of Earth-bound SEPs using real-time data. Since the largest, most\n",
    "impactful events occur infrequently, some regions of the feature space are sparse and\n",
    "simple discrete binning procedures have limitations. The goal of this project is to\n",
    "improve upon the empirical SEP proton prediction forecast model (PROTONS) currently\n",
    "in operational use at SWPC, through the application of modern machine learning\n",
    "techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "from datetime import datetime,timedelta\n",
    "\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict, GridSearchCV\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from scipy.sparse import csr_matrix, find\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading in the SEP and control data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read in the Balch SEP event list\n",
    "sepdata = pd.read_excel(\"SPEall.v7p.xls\")\n",
    "\n",
    "#read in the Balch SEP event list\n",
    "ctrldata = pd.read_excel(\"ctrlevents.v8p.xls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Onset',\n",
       " 'Threshold',\n",
       " 'Maxtime',\n",
       " 'Maxflux',\n",
       " 'Endtime',\n",
       " 'EPSSatId',\n",
       " 'FlrOnset',\n",
       " 'Flrmaxtime',\n",
       " 'Flrendtime',\n",
       " 'FlrPeakFlux',\n",
       " 'xrscls',\n",
       " 'ocls',\n",
       " 'optlocation',\n",
       " 'region',\n",
       " 'TypeII',\n",
       " 'TII_Duration',\n",
       " 'TypeIV',\n",
       " 'TIV_duration',\n",
       " 'CME_speed',\n",
       " 'XRSSatId',\n",
       " 'FlrHpTime',\n",
       " 'FlrIntFlux',\n",
       " 'FlrIntFlux2',\n",
       " 'P10MAX',\n",
       " 'P30MAX',\n",
       " 'P60MAX',\n",
       " 'P100MAX',\n",
       " 'P10FLUENCE',\n",
       " 'P30FLUENCE',\n",
       " 'P60FLUENCE',\n",
       " 'P100FLUENCE',\n",
       " 'SEP']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(sepdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FlrOnset',\n",
       " 'Flrmaxtime',\n",
       " 'Flrendtime',\n",
       " 'FlrPeakFlux',\n",
       " 'xrscls',\n",
       " 'ocls',\n",
       " 'optlocation',\n",
       " 'region',\n",
       " 'Rpatrol',\n",
       " 'Type II',\n",
       " 'TII Duration',\n",
       " 'Type IV',\n",
       " 'TIV duration',\n",
       " 'CME Patrol',\n",
       " 'CME onset',\n",
       " 'CME speed',\n",
       " 'Satellite',\n",
       " 'FlrHpTime',\n",
       " 'FlrIntFlux',\n",
       " 'FlrIntFlux2',\n",
       " 'Association',\n",
       " 'S1onset',\n",
       " 'S2onset',\n",
       " 'S3onset',\n",
       " 'S4onset',\n",
       " 'S5onset',\n",
       " 'GT100onset',\n",
       " 'SEP']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ctrldata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\"> **Gah, the sepdata and ctrldata dataframes DO NOT have the same columns. At some point we'll need to make a master list with both sep and \"all clear\" events, but for right now, just to get the feature engineering pipeline up and running, I'm just going to label half of the sep events as being all clear, just to give me two classes.**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#add y label column indicating positive and negative SEP events\n",
    "#sepdata['SEP'] = 1\n",
    "#ctrldata['SEP'] = 0\n",
    "\n",
    "#merge sep events and control events\n",
    "#allevts = pd.concat([sepdata, ctrldata])\n",
    "\n",
    "#shuffle the events so they are not organized \n",
    "#allevts_shuffled = shuffle(allevts)\n",
    "\n",
    "#save the shuffled dataframe\n",
    "#allevts.to_csv(\"AllEvtsShuffled.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hazelbain/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "#adding y label column indicating positive and negative SEP events (HACK 50/50 pos and neg to test pipeline)\n",
    "sepdata['SEP'] = 0\n",
    "sepdata.SEP[0:int(len(sepdata)/2)] = 1\n",
    "\n",
    "#shuffle the events so they are not organized \n",
    "allevts_shuffled = shuffle(sepdata)\n",
    "\n",
    "#save the shuffled dataframe\n",
    "allevts_shuffled.to_csv(\"AllEvtsShuffled.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make Scatterplot matrix showing relationship between parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.plotting.scatter_matrix(sepdata[['Maxflux','FlrPeakFlux','TII_Duration','TIV_duration',\\\n",
    "#                            'FlrIntFlux','FlrIntFlux2','P10MAX','P30MAX','P60MAX',\\\n",
    "#                            'P100MAX','P10FLUENCE','P30FLUENCE','P60FLUENCE','P100FLUENCE']], \\\n",
    "#                            figsize=(18,18), diagonal='kde')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logisitic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class to exract features from dataframe that can be used directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RawFeatures(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def fit(self, examples):\n",
    "        # return self and nothing else \n",
    "        return self\n",
    "    \n",
    "    def get_feature_names(self):\n",
    "        \"\"\"Array mapping from feature integer indices to feature name\"\"\"\n",
    "        \n",
    "        return [\"FlTim2Pk\"]\n",
    "    \n",
    "    def transform(self, examples):\n",
    "        \n",
    "        # Initiaize matrix \n",
    "        X = np.zeros((len(examples),1))           \n",
    "        \n",
    "        ## TODO\n",
    "        \n",
    "        #time between flare max and flare onset\n",
    "        #X[ii,:] = examples.Flrmaxtime - examples.FlrOnset\n",
    "        \n",
    "        return(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class to create feature with the time between flare onset to flare max time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class FlareTime2Peak(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def fit(self, examples):\n",
    "        # return self and nothing else \n",
    "        return self\n",
    "    \n",
    "    def get_feature_names(self):\n",
    "        \"\"\"Array mapping from feature integer indices to feature name\"\"\"\n",
    "        \n",
    "        return [\"FlTim2Pk\"]\n",
    "    \n",
    "    def transform(self, examples):\n",
    "        \n",
    "        # Initiaize matrix \n",
    "        X = np.zeros((len(examples),1))           \n",
    "\n",
    "        #time between flare max and flare onset\n",
    "        X[:,0] = np.asarray([(mx - on).seconds for mx, on in zip(examples.Flrmaxtime, examples.Onset)])\n",
    "        \n",
    "        return(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SEPClass:\n",
    "    def __init__(self):        # <--- other keywords to be used by Feature Union go here\n",
    "        \n",
    "        #Set up the Feature union to combine Feature creating classes\n",
    "        self.allmyfeatures = FeatureUnion([\n",
    "            (\"RawFeat\", RawFeatures()),\n",
    "            (\"FlareTime2Peak\", FlareTime2Peak())   #,\n",
    "            ])\n",
    "    \n",
    "    def build_train_features(self, examples):\n",
    "        \"\"\"\n",
    "        Method to take in training text features and do further feature engineering \n",
    "        Most of the work in this homework will go here, or in similar functions  \n",
    "        :param examples: currently just a list of forum posts  \n",
    "        \"\"\"  \n",
    "        \n",
    "        ##convert columns of time from string to datetime -- MOVE TO SEPARATE FUNCTION\n",
    "        examples.Onset = pd.Series(datetime.strptime(t, \"%Y-%m-%dT%H:%M:%S.%f\") for t in examples.Onset)\n",
    "        examples.Flrmaxtime = pd.Series(datetime.strptime(t, \"%Y-%m-%dT%H:%M:%S.%f\") for t in examples.Flrmaxtime)\n",
    "        examples.Flrendtime = pd.Series(datetime.strptime(t, \"%Y-%m-%dT%H:%M:%S.%f\") for t in examples.Flrendtime)\n",
    "        examples.FlrHpTime = pd.Series(datetime.strptime(t, \"%Y-%m-%dT%H:%M:%S.%f\") for t in examples.FlrHpTime)\n",
    "        \n",
    "        return self.allmyfeatures.fit_transform(examples)\n",
    "        \n",
    "\n",
    "    def get_test_features(self, examples):\n",
    "        \"\"\"\n",
    "        Method to take in test text features and transform the same way as train features \n",
    "        :param examples: currently just a list of forum posts  \n",
    "        \"\"\"\n",
    "    \n",
    "        return self.allmyfeatures.transform(examples)\n",
    "\n",
    "    def show_topX(self, num=3):\n",
    "        \"\"\"\n",
    "        prints the top num features for the positive class and the \n",
    "        top 10 features for the negative class. \n",
    "        \"\"\"\n",
    "        feature_names = np.asarray([x.split(\"__\")[1] for x in self.allmyfeatures.get_feature_names()])\n",
    "        topX = np.argsort(self.logreg.coef_[0])[-num:]\n",
    "        bottomX = np.argsort(self.logreg.coef_[0])[:num]\n",
    "        \n",
    "        print(\"\\nTop 3 features for Pos and Neg\\n-------------------------\")\n",
    "        for fn in np.arange(1,num):\n",
    "            print(\"Pos %i: %s %f\" % (fn, feature_names[topX[-fn]], self.logreg.coef_[0,topX[-fn]]))\n",
    "        for fn in np.arange(0,num-1):\n",
    "            print(\"Neg %i: %s %f\" % (fn, feature_names[bottomX[fn]], self.logreg.coef_[0,bottomX[fn]]))\n",
    "\n",
    "      \n",
    "    def show_misclassified(self):     \n",
    "\n",
    "        \"\"\"\n",
    "        Method to show the misclassified examples i.e. False Positives and False negatives \n",
    "        \"\"\"\n",
    "        \n",
    "        #get all the feature names\n",
    "        words = feat.allmyfeatures.get_feature_names()\n",
    "        \n",
    "        # False positives\n",
    "        print(\"\\nSome misclassified examples:\")\n",
    "        falsepos = np.where((self.train_pred != self.y_train) & (self.train_pred == 1))[0]   #all false pos example rows\n",
    "        print(\"\\nPredicted SEP but labeled AllClear (False Pos) \\n------------------------- \")\n",
    "\n",
    "        for i in range(len(falsepos[0:10])):         #loop through falsepos examples\n",
    "            weights_falsepos = []\n",
    "            x = find(feat.X_train[falsepos[i]])      #find which features are used for this example\n",
    "            for ii in x[1]:                          #from sparse matrix get column indices corresponding to features\n",
    "                weights_falsepos.append((words[ii].split('__')[1], self.logreg.coef_[0,ii]))      #get the word and weight\n",
    "\n",
    "            print(\"label: %i, prediction %i, Neg Prob: %f, Pos Prob: %f, Ex No.: %i,  example: %s \" % \\\n",
    "                (self.y_train[falsepos[i]], self.train_pred[falsepos[i]] , self.train_pred_prob[falsepos[i]][0], \\\n",
    "                     self.train_pred_prob[falsepos[i]][1], falsepos[i], self.clean_examples[falsepos[i]]))\n",
    "            for j in weights_falsepos:\n",
    "                print(j)\n",
    "                \n",
    "        # False Negatives\n",
    "        falseneg = np.where((self.train_pred != self.y_train) & (self.train_pred == 0))[0]\n",
    "        print(\"\\nPredicted AllClear but labeled SEP (False Neg) \\n-------------------------\")\n",
    "\n",
    "        for i in range(len(falseneg[0:10])):\n",
    "            weights_falseneg = []\n",
    "            x = find(feat.X_train[falseneg[r]])\n",
    "            for ii in x[1]:\n",
    "                weights_falseneg.append((words[ii].split('__')[1], self.logreg.coef_[0,ii])) \n",
    "\n",
    "            print(\"label: %i, prediction %i, Neg Prob: %f, Pos Prob: %f, Ex No.: %i, \\nexample: %s \" % \\\n",
    "                (self.y_train[falseneg[i]], self.train_pred[falseneg[i]], self.train_pred_prob[falseneg[i]][0], \\\n",
    "                 self.train_pred_prob[falseneg[i]][1], falseneg[i], self.clean_examples[falseneg[i]]))\n",
    "            for j in weights_falseneg:\n",
    "                print(j)\n",
    "        \n",
    "        print(\"\\n\\n\")\n",
    "       \n",
    "\n",
    "    def score(self, predictions, y, dfTrain):\n",
    "\n",
    "        \"\"\"find the accuracy score given the labels and the predictions\"\"\"\n",
    "        \n",
    "        print(\"Accuracy: %f\" % accuracy_score(y, predictions))\n",
    "\n",
    "\n",
    "    def train_model(self, random_state=1234):\n",
    "        \"\"\"\n",
    "        Method to read in training data from file, and \n",
    "        train Logistic Regression classifier. \n",
    "        \n",
    "        :param random_state: seed for random number generator \n",
    "        \"\"\"\n",
    "        \n",
    "        from sklearn.linear_model import LogisticRegression \n",
    "        \n",
    "        # load data \n",
    "        self.dfTrain = pd.read_csv(\"AllEvtsShuffled.csv\")\n",
    "                      \n",
    "        # get training features and labels \n",
    "        self.X_train = self.build_train_features(self.dfTrain)    #CHANGE\n",
    "        self.y_train = np.array(self.dfTrain.SEP, dtype=int)\n",
    "        \n",
    "        #print the shape of the features\n",
    "        print(\"Shape of the Features: Num examples x Num Features\")\n",
    "        print(self.X_train.shape)\n",
    "        \n",
    "        # train logistic regression model.  !!You MAY NOT CHANGE THIS!! \n",
    "        self.logreg = LogisticRegression(random_state=random_state)\n",
    "        self.logreg.fit(self.X_train, self.y_train)\n",
    "\n",
    "        # make predictions on training data \n",
    "        self.train_pred = self.logreg.predict(self.X_train)\n",
    "\n",
    "        #return the LogReg probabilities used to classify each example  \n",
    "        self.train_pred_prob = self.logreg.predict_proba(self.X_train)\n",
    "        \n",
    "        print(\"\\nTraining Set\\n-------------------------\")\n",
    "        self.score(self.train_pred, self.y_train, self.dfTrain)\n",
    "             \n",
    "        #cross validation\n",
    "        folds = 2\n",
    "        \n",
    "        print(\"\\nCross Validation Accuracy Scores (cross_val_score)\\n-------------------------\")\n",
    "        scores = cross_val_score(self.logreg, self.X_train, self.y_train, cv=folds)\n",
    "        print(scores)\n",
    "        print(\"\\nMean Accuracy in Cross-Validation = %.3f \\n\" % scores.mean())\n",
    "        \n",
    "        #cross validation\n",
    "        print(\"\\nCross Validation Accuracy Scores (cross_val_predict)\\n-------------------------\")\n",
    "        self.y_pred = cross_val_predict(self.logreg, self.X_train, self.y_train, cv=folds)\n",
    "        print(self.score(self.y_pred, self.y_train, self.X_train))\n",
    "        \n",
    "        print(\"\\nCross Confusion Matrix\\n-------------------------\")\n",
    "        self.conf_mat = confusion_matrix(self.y_train,self.y_pred)\n",
    "        tn, fp, fn, tp = self.conf_mat.ravel()\n",
    "        print(\"True Pos: %i, True Neg: %i, False Pos: %i,. False Neg: %i\" % (tp,tn,fp,fn))\n",
    "        \n",
    "          \n",
    "        \n",
    "    def model_predict(self):\n",
    "        \"\"\"\n",
    "        Method to read in test data from file, make predictions\n",
    "        using trained model, and dump results to file \n",
    "        \"\"\"\n",
    "        \n",
    "        # read in test data \n",
    "        dfTest  = pd.read_csv(\"../data/spoilers/test.csv\")\n",
    "        \n",
    "        # featurize test data \n",
    "        self.X_test = self.get_test_features(list(dfTest[\"sentence\"]))\n",
    "        \n",
    "        # make predictions on test data \n",
    "        pred = self.logreg.predict(self.X_test)\n",
    "        \n",
    "        # dump predictions to file for submission to Kaggle  \n",
    "        pd.DataFrame({\"spoiler\": np.array(pred, dtype=bool)}).to_csv(\"prediction.csv\", index=True, index_label=\"Id\")\n",
    "        \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the Features: Num examples x Num Features\n",
      "(127, 1)\n",
      "\n",
      "Training Set\n",
      "-------------------------\n",
      "Accuracy: 0.503937\n",
      "\n",
      "Cross Validation Accuracy Scores (cross_val_score)\n",
      "-------------------------\n",
      "[ 0.5         0.50793651]\n",
      "\n",
      "Mean Accuracy in Cross-Validation = 0.504 \n",
      "\n",
      "\n",
      "Cross Validation Accuracy Scores (cross_val_predict)\n",
      "-------------------------\n",
      "Accuracy: 0.503937\n",
      "None\n",
      "\n",
      "Cross Confusion Matrix\n",
      "-------------------------\n",
      "True Pos: 0, True Neg: 64, False Pos: 0,. False Neg: 63\n"
     ]
    }
   ],
   "source": [
    "#Initialize SEPClass instance\n",
    "sep = SEPClass()\n",
    "\n",
    "#Turn off features that aren't fully fleshed out or don't work\n",
    "sep.allmyfeatures.set_params(RawFeat=None)\n",
    "\n",
    "#train the model\n",
    "sep.train_model(random_state=1230)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
