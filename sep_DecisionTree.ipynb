{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' DECISION TREE ALGORITHM FOR SEP CLASSIFICATION '''\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "from datetime import datetime,timedelta\n",
    "\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, make_scorer, recall_score, matthews_corrcoef\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict, GridSearchCV\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, ClassifierMixin\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, brier_score_loss, precision_score\n",
    "from sklearn.metrics import brier_score_loss as bsl\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "#import scikitplot as skplt\n",
    "\n",
    "\n",
    "from scipy.sparse import csr_matrix, find\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' read in the Balch SEP event list '''\n",
    "\n",
    "sepdata = pd.read_excel(\"SPEall.v7p.xls\")\n",
    "\n",
    "#read in the Balch SEP event list\n",
    "old_data = pd.read_excel(\"ctrlevents.v8p.xls\")\n",
    "\n",
    "#read in the student event list\n",
    "old_data = pd.read_excel(\"ControlEvents_student.xls\")\n",
    "old_data.TypeII = (old_data.TypeII.str.lower() == \"yes\").astype(int)\n",
    "old_data.TypeIV = (old_data.TypeIV.str.lower() == \"yes\").astype(int)\n",
    "\n",
    "#adding y label column indicating positive and negative SEP events - SEP events have Association = ProtonFlare\n",
    "#old_data['sep'] = (old_data.Association == \"ProtonFlare\").astype(int)\n",
    "old_data['sep'] = old_data.Association.str.contains('^Proton').astype(int)\n",
    "\n",
    "\n",
    "new_data = pd.read_csv('new_sep.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_data_old = old_data[['FlrOnset','Flrmaxtime','FlrPeakFlux','FlrIntFlux2','TypeII','TypeIV','optlocation','tchianti','emchianti','FlrIntFlux','sep']]\n",
    "feature_data_new = new_data[['FlrOnset','Flrmaxtime','FlrPeakFlux','FlrIntFlux2','TypeII','TypeIV','optlocation','tchianti','emchianti','FlrIntFlux','sep']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.concat([feature_data_old,feature_data_new])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Remove rows where optlocation = nan\n",
    "old_data = old_data[old_data.optlocation.astype('str') != 'nan']\n",
    "#shuffle the events so they are not organized \n",
    "old_data = shuffle(old_data)\n",
    "#save the shuffled dataframe -- commented out to prevent resaving\n",
    "old_data.to_csv(\"AllEvtsShuffled_student_PB.csv\")\n",
    "\n",
    "# Remove rows where optlocation = nan\n",
    "data = data[data.optlocation.astype('str') != 'nan']\n",
    "#shuffle the events so they are not organized \n",
    "data = shuffle(data)\n",
    "#save the shuffled dataframe -- commented out to prevent resaving\n",
    "data.to_csv(\"AllEvtsShuffled_PB.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BalchPaperFeatures(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        \"\"\"Class to create original 4 features from Balch 2008\"\"\"\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def fit(self, examples):\n",
    "        # return self and nothing else \n",
    "        return self\n",
    "    \n",
    "    def get_feature_names(self):\n",
    "        \"\"\"Array mapping from feature integer indices to feature name\"\"\"\n",
    "        \n",
    "        return ['FlrPeakFlux','FlrIntFlux','TypeII','TypeIV']\n",
    "    \n",
    "    def transform(self, examples):\n",
    "                \n",
    "        #Choose the orginal 4 Balch 2008 features (5 if you include both type II and type Iv as separate features)\n",
    "        #X = examples[['FlrPeakFlux','FlrIntFlux','Type24']]\n",
    "        X = examples[['FlrPeakFlux','FlrIntFlux2','TypeII','TypeIV']]\n",
    "        #temp = np.logical_or(examples['TypeII'],examples['TypeIV'])\n",
    "        #X['TypeII_IV'] = temp\n",
    "        \n",
    "\n",
    "        return(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RawFeatures(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        \"\"\"Ogher features from the Event List that don't need to be manipulated before being included in model\"\"\"\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def fit(self, examples):\n",
    "        # return self and nothing else \n",
    "        return self\n",
    "    \n",
    "    def get_feature_names(self):\n",
    "        \"\"\"Array mapping from feature integer indices to feature name\"\"\"\n",
    "        \n",
    "        return ['FlrIntFlux','tchianti','emchianti']\n",
    "    \n",
    "    def transform(self, examples):\n",
    "                \n",
    "        #Choose the orginal 4 Balch 2008 features (5 if you include both type II and type Iv as separate features)\n",
    "        X = examples[['FlrIntFlux','tchianti','emchianti']]\n",
    "\n",
    "        return(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FlareTime2Peak(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    \"\"\"Class to create feature with the time between flare onset to flare max time\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def fit(self, examples):\n",
    "        # return self and nothing else \n",
    "        return self\n",
    "    \n",
    "    def get_feature_names(self):\n",
    "        \"\"\"Array mapping from feature integer indices to feature name\"\"\"\n",
    "        \n",
    "        return [\"FlTim2Pk\"]\n",
    "    \n",
    "    def transform(self, examples):\n",
    "        \n",
    "        # Initiaize matrix \n",
    "        X = np.zeros((len(examples),1))           \n",
    "\n",
    "        #time between flare max and flare onset\n",
    "        X[:,0] = np.asarray([(mx - on).seconds for mx, on in zip(examples.Flrmaxtime, examples.FlrOnset)])\n",
    "        \n",
    "        return(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LocationFeatures(BaseEstimator, TransformerMixin):\n",
    "   \n",
    "    \"\"\"Class to create feature with the time between flare onset to flare max time\"\"\"\n",
    "   \n",
    "    def __init__(self):\n",
    "       \n",
    "        return None\n",
    "   \n",
    "    def fit(self, examples):\n",
    "        # return self and nothing else \n",
    "        return self\n",
    "   \n",
    "    def get_feature_names(self):\n",
    "        \"\"\"Array mapping from feature integer indices to feature name\"\"\"\n",
    "       \n",
    "        return ['Loc']\n",
    "   \n",
    "    def transform(self, examples):\n",
    "       \n",
    "        # Initiaize matrix \n",
    "        X = np.zeros((len(examples),2))  \n",
    "       \n",
    "        #time between flare max and flare onset\n",
    "        #X[:,0] = np.asarray([str(x)[1:3] for x in examples.optlocation])   #north - south\n",
    "        #X[:,1] = np.asarray([str(x)[4::] for x in examples.optlocation])   #north - south\n",
    "       \n",
    "        for i,loc in enumerate(examples.optlocation):\n",
    "            lat = str(loc)[1:3]\n",
    "            if str(loc)[0] == 's' or str(loc)[0] == 'S':\n",
    "                X[i,0] = -int(lat)\n",
    "            else:\n",
    "                X[i,0] = (lat)\n",
    "\n",
    "            #west-east\n",
    "            long = str(loc)[4::]\n",
    "            if str(loc)[3] == 'w' or str(loc)[3] == 'W':\n",
    "                X[i,1] = -int(long)\n",
    "            else:\n",
    "                X[i,1] = int(long)\n",
    "\n",
    "        return(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SEPClass(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, estimator, folds = 6, threshold=0.5):        # <--- other keywords to be used by Feature Union go here\n",
    "        \n",
    "        \"\"\"Class to fit and train Logistic Regression algorithm for SEP forecasting\n",
    "        \n",
    "        Input keywords:\n",
    "        \n",
    "        folds:        Number of cross validation folds to use\n",
    "        threshold:    Decision Boundary threshold\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        self.estimator = estimator     #estimator to use for classification e.g. LogReg or SVM\n",
    "        self.folds = folds             #cross validation folds for estimator\n",
    "        self.threshold = threshold     #decision boundary threshold\n",
    "    \n",
    "        #Set up the Feature union to combine Feature creating classes\n",
    "        self.allmyfeatures = FeatureUnion([\n",
    "            (\"BalchFeat\", BalchPaperFeatures()),\n",
    "            (\"RawFeat\", RawFeatures()),\n",
    "            (\"LocFeatures\", LocationFeatures())#,\n",
    "            #(\"FlareTime2Peak\", FlareTime2Peak())   \n",
    "        ])\n",
    "    \n",
    "    def build_train_features(self, examples):\n",
    "        \"\"\"\n",
    "        Method to take in training text features and do further feature engineering \n",
    "        Most of the work in this homework will go here, or in similar functions  \n",
    "        :param examples: currently just a list of forum posts  \n",
    "        \"\"\"  \n",
    "        \n",
    "        ##convert columns of time from string to datetime -- MOVE TO SEPARATE CLEANING FUNCTION\n",
    "        examples.FlrOnset = pd.Series(datetime.strptime(t, \"%Y-%m-%dT%H:%M:%S.%f\") for t in examples.FlrOnset)\n",
    "        examples.Flrmaxtime = pd.Series(datetime.strptime(t, \"%Y-%m-%dT%H:%M:%S.%f\") for t in examples.Flrmaxtime)\n",
    "        #examples.Flrendtime = pd.Series(datetime.strptime(t, \"%Y-%m-%dT%H:%M:%S.%f\") for t in examples.Flrendtime)\n",
    "        #examples.FlrHpTime = pd.Series(datetime.strptime(t, \"%Y-%m-%dT%H:%M:%S.%f\") for t in examples.FlrHpTime)\n",
    "        \n",
    "        ##convert Type II and Type IV \"yes/no\" to binary\n",
    "        #print(examples.TypeII)\n",
    "        #examples.TypeII = (examples.TypeII.str.lower() == \"yes\").astype(int)\n",
    "        #examples.TypeIV = (examples.TypeIV.str.lower() == \"yes\").astype(int)\n",
    "        #examples['Type24'] = np.logical_or(examples.TypeII, examples.TypeIV)\n",
    "        \n",
    "        return self.allmyfeatures.fit_transform(examples)\n",
    "        #normalize data here?\n",
    "\n",
    "    def get_test_features(self, examples):\n",
    "        \"\"\"\n",
    "        Method to take in test text features and transform the same way as train features \n",
    "        :param examples: currently just a list of forum posts  \n",
    "        \"\"\"\n",
    "    \n",
    "        return self.allmyfeatures.transform(examples)\n",
    "\n",
    "    def show_topX(self, num=3):\n",
    "        \"\"\"\n",
    "        prints the top num features for the positive class and the \n",
    "        top 10 features for the negative class. \n",
    "        \"\"\"\n",
    "        feature_names = np.asarray([x.split(\"__\")[1] for x in self.allmyfeatures.get_feature_names()])\n",
    "        topX = np.argsort(self.estimator.coef_[0])[-num:]\n",
    "        bottomX = np.argsort(self.estimator.coef_[0])[:num]\n",
    "        \n",
    "        print(feature_names)\n",
    "        \n",
    "        print(\"\\nTop 3 features for Pos and Neg\\n-------------------------\")\n",
    "        for fn in np.arange(1,num):\n",
    "            print(\"Pos %i: %s %f\" % (fn, feature_names[topX[-fn]], self.estimator.coef_[0,topX[-fn]]))\n",
    "        for fn in np.arange(0,num-1):\n",
    "            print(\"Neg %i: %s %f\" % (fn, feature_names[bottomX[fn]], self.estimator.coef_[0,bottomX[fn]]))\n",
    "            \n",
    "      \n",
    "    def show_misclassified(self):     \n",
    "\n",
    "        \"\"\"\n",
    "        Method to show the misclassified examples i.e. False Positives and False negatives \n",
    "        \"\"\"\n",
    "        \n",
    "        #get all the feature names\n",
    "        #words = feat.allmyfeatures.get_feature_names() #####\n",
    "        words = self.allmyfeatures.get_feature_names() #####\n",
    "        \n",
    "        # False positives\n",
    "        print(\"\\nSome misclassified examples:\")\n",
    "        falsepos = np.where((self.train_pred != self.y_train) & (self.train_pred == 1))[0]   #all false pos example rows\n",
    "        print(\"\\nPredicted SEP but labeled AllClear (False Pos) \\n------------------------- \")\n",
    "\n",
    "        for i in range(len(falsepos[0:10])):         #loop through falsepos examples\n",
    "            weights_falsepos = []\n",
    "            x = find(feat.X_train[falsepos[i]])      #find which features are used for this example\n",
    "            for ii in x[1]:                          #from sparse matrix get column indices corresponding to features\n",
    "                weights_falsepos.append((words[ii].split('__')[1], self.estimator.coef_[0,ii]))      #get the word and weight\n",
    "\n",
    "            print(\"label: %i, prediction %i, Neg Prob: %f, Pos Prob: %f, Ex No.: %i,  example: %s \" % \\\n",
    "                (self.y_train[falsepos[i]], self.train_pred[falsepos[i]] , self.train_pred_prob[falsepos[i]][0], \\\n",
    "                     self.train_pred_prob[falsepos[i]][1], falsepos[i], self.clean_examples[falsepos[i]]))\n",
    "            for j in weights_falsepos:\n",
    "                print(j)\n",
    "                \n",
    "        # False Negatives\n",
    "        falseneg = np.where((self.train_pred != self.y_train) & (self.train_pred == 0))[0]\n",
    "        print(\"\\nPredicted AllClear but labeled SEP (False Neg) \\n-------------------------\")\n",
    "\n",
    "        for i in range(len(falseneg[0:10])):\n",
    "            weights_falseneg = []\n",
    "            x = find(feat.X_train[falseneg[r]])\n",
    "            for ii in x[1]:\n",
    "                weights_falseneg.append((words[ii].split('__')[1], self.estimator.coef_[0,ii])) \n",
    "\n",
    "            print(\"label: %i, prediction %i, Neg Prob: %f, Pos Prob: %f, Ex No.: %i, \\nexample: %s \" % \\\n",
    "                (self.y_train[falseneg[i]], self.train_pred[falseneg[i]], self.train_pred_prob[falseneg[i]][0], \\\n",
    "                 self.train_pred_prob[falseneg[i]][1], falseneg[i], self.clean_examples[falseneg[i]]))\n",
    "            for j in weights_falseneg:\n",
    "                print(j)\n",
    "        \n",
    "        print(\"\\n\\n\")\n",
    "        print(words)\n",
    "       \n",
    "    def show_report(self):\n",
    "        \n",
    "        \"\"\"Method to show a report card of the model fit \"\"\"\n",
    "        \n",
    "        # Add confusion Matrix\n",
    "        tn, fp, fn, tp=confusion_matrix(self.y_train, self.y_train_pred).ravel()\n",
    "        print(\"True Pos: %i, True Neg: %i, False Pos: %i,. False Neg: %i\\n\" % (tp,tn,fp,fn))\n",
    "\n",
    "        #calculate the mean square error\n",
    "        mserr = mse(self.y_train, self.y_train_pred)\n",
    "        print(\"MSE: %.4f\" % mserr)\n",
    "\n",
    "        #calculate the Brier score - is this the same as the MSE? And QR referenced in Balch paper?\n",
    "        bsloss = bsl(self.y_train, self.y_train_pred_prob[:,1])\n",
    "        print(\"BSL: %.4f\" % bsloss)\n",
    "\n",
    "        #Occurance rate = #SEPS / #events\n",
    "        occ_rate = self.y_train.sum()/len(self.y_train)\n",
    "\n",
    "        #Reference score of predicting all negative class\n",
    "        #QR_star = 0.0324 Balch\n",
    "        QR_star =  mse(self.y_train, np.zeros(len(self.y_train)))\n",
    "        print(\"RefQuadScore: %.4f\\n\" % QR_star)\n",
    "\n",
    "        #assume the QR is the same as the MSE - as stated later in Balch\n",
    "        QR = mserr\n",
    "        #QR = 0.0250 Balch\n",
    "\n",
    "        #skill score \n",
    "        SS = (QR_star - QR)/QR_star\n",
    "        print(\"SS: %.4f\" % SS)\n",
    "\n",
    "        FAR = fp/(tp + fp)\n",
    "        POD = tp/(tp + fn)\n",
    "        TSS = tp / (tp+fp+fn)\n",
    "        E = ((tp + fn)*(tp + fp) + (fp + tn)*(fn + tn)) / self.X_train.shape[0]\n",
    "        HSS = (tp + tn - E)/(self.X_train.shape[0] - E)\n",
    "\n",
    "        print(\"FAR: %.4f\" % FAR)\n",
    "        print(\"POD: %.4f\" % POD)\n",
    "        print(\"TSS: %.4f\" % TSS)\n",
    "        print(\"HSS: %.4f\" % HSS)\n",
    "        \n",
    "        ##ROC metrics\n",
    "        fpr, tpr, thresh = roc_curve(self.y_train, self.y_train_pred, drop_intermediate=False)\n",
    "\n",
    "    def roc_curve(self):\n",
    "        \n",
    "        \"\"\"plot and ROC curve\"\"\"\n",
    "        \n",
    "        # Initial implementation of ROC plot applied to training set\n",
    "        skplt.metrics.plot_roc_curve(self.y_train, self.y_train_probas)\n",
    "        \n",
    "    def score(self, X, y):\n",
    "\n",
    "        \"\"\"find the accuracy score given the training data and labels\"\"\"\n",
    "        #print(\"...In Score...\")\n",
    "        #print(\"threshold:\", self.threshold)\n",
    "        \n",
    "        y_pred = (self.estimator.predict(X) > self.threshold).astype(int)\n",
    "        \n",
    "        #tn, fp, fn, tp=confusion_matrix(y, y_pred).ravel()\n",
    "        #return tp/(tp+fp+fn)\n",
    "        \n",
    "        return accuracy_score(y, y_pred)\n",
    "        \n",
    "    def fit(self, X, y):    #, random_state=1234):\n",
    "        \"\"\"\n",
    "        Method to read in training data from file, and \n",
    "        train Logistic Regression classifier. \n",
    "        \n",
    "        :param random_state: seed for random number generator \n",
    "        \"\"\"\n",
    "        \n",
    "        from sklearn.linear_model import LogisticRegression \n",
    "        \n",
    "        # load data \n",
    "        #self.dfTrain = pd.read_csv(\"AllEvtsShuffled.csv\")\n",
    "                      \n",
    "        # get training features and labels \n",
    "        #self.X_train = self.build_train_features(self.dfTrain)    #CHANGE\n",
    "        #self.y_train = np.array(self.dfTrain.sep, dtype=int)\n",
    "        \n",
    "        self.X_train = X \n",
    "        self.y_train = y \n",
    "        \n",
    "        #print the shape of the features\n",
    "        print(\"Shape of the Features: Num examples x Num Features\")\n",
    "        print(self.X_train.shape)\n",
    "        #print(\"examples...:\", self.X_train[0:10])\n",
    "\n",
    "        #self.logreg.fit(self.X_train, self.y_train)\n",
    "        self.estimator.fit(self.X_train, self.y_train)\n",
    "        \n",
    "        # make predictions on training data \n",
    "        self.y_train_pred = self.estimator.predict(self.X_train)\n",
    "\n",
    "        #return the LogReg probabilities used to classify each example  \n",
    "        self.y_train_pred_prob = self.estimator.predict_proba(self.X_train)\n",
    "        \n",
    "        print(\"\\nTRAINING SET\\n-------------------------------------------------------------\")\n",
    "        #self.score(self.train_pred, self.y_train)\n",
    "             \n",
    "        #cross validation\n",
    "         \n",
    "        metric1 = 'recall'\n",
    "        metric2 = 'precision'\n",
    "    \n",
    "        metric3s = 'matthews correlation coefficient' \n",
    "        metric3 = make_scorer(matthews_corrcoef)\n",
    "        \n",
    "        metric4s = \"brier score\" \n",
    "        metric4 = make_scorer(brier_score_loss)\n",
    "        \n",
    "        #print(\"\\nCross Validation Metric Scores (\", metric4s, \")\\n-------------------------\")\n",
    "        #scores = cross_val_score(self.estimator, self.X_train, self.y_train, cv=self.folds,scoring=metric4)\n",
    "        #print(scores)\n",
    "        #print(\"\\nMean Accuracy in Cross-Validation = %.3f \\n\" % scores.mean())\n",
    "        \n",
    "        print(\"\\nCross Validation Metric Scores\\n-----------------------------------\\n\")\n",
    "        rec_score = cross_val_score(self.estimator, self.X_train, self.y_train, cv=self.folds,scoring=metric1)\n",
    "        prec_score = cross_val_score(self.estimator, self.X_train, self.y_train, cv=self.folds,scoring=metric2)\n",
    "        mattco_score = cross_val_score(self.estimator, self.X_train, self.y_train, cv=self.folds,scoring=metric3)\n",
    "        brier_score = cross_val_score(self.estimator, self.X_train, self.y_train, cv=self.folds,scoring=metric4)\n",
    "        \n",
    "        print(metric1,'\\n')\n",
    "        print(rec_score,'\\n-------------------------\\n')\n",
    "        \n",
    "        print(metric2,'\\n')\n",
    "        print(prec_score,'\\n-------------------------\\n')\n",
    "        \n",
    "        print(metric3s,'\\n')\n",
    "        print(mattco_score,'\\n-------------------------\\n')\n",
    "        \n",
    "        print(metric4s,'\\n')\n",
    "        print(brier_score,'\\n-------------------------\\n')\n",
    "        \n",
    "        #cross validation\n",
    "        \n",
    "        #cross validation\n",
    "        #print(\"\\nCross Validation Accuracy Scores (cross_val_predict)\\n-------------------------\")\n",
    "        #self.y_pred = cross_val_predict(self.estimator, self.X_train, self.y_train, cv=self.folds)\n",
    "        #print(self.score(self.y_pred, self.y_train))\n",
    "        \n",
    "        #print(\"\\nCross Confusion Matrix\\n-------------------------\")\n",
    "        #self.conf_mat = confusion_matrix(self.y_train,self.y_pred)\n",
    "        #tn, fp, fn, tp = self.conf_mat.ravel()\n",
    "        #print(\"True Pos: %i, True Neg: %i, False Pos: %i,. False Neg: %i\" % (tp,tn,fp,fn))\n",
    "        \n",
    "        #training set score (no cross-validation)\n",
    "        print('\\nTraining Set (no cross-validation) Score \\n-----------------------------------\\n')\n",
    "        \n",
    "        rec1_score = recall_score(self.y_train,self.y_train_pred)\n",
    "        prec1_score = precision_score(self.y_train,self.y_train_pred)\n",
    "        mattco1_score = matthews_corrcoef(self.y_train,self.y_train_pred)\n",
    "        \n",
    "        print(metric1,'\\n')\n",
    "        print(rec1_score,'\\n-------------------------\\n')\n",
    "        \n",
    "        print(metric2,'\\n')\n",
    "        print(prec1_score,'\\n-------------------------\\n')\n",
    "        \n",
    "        print(metric3s,'\\n')\n",
    "        print(mattco1_score,'\\n-------------------------\\n')\n",
    "        \n",
    "        #brier score is already on report card\n",
    "        print('Briar Score (BSL) on report card\\n')\n",
    "        print('-------------------------------------------------------------\\n')\n",
    "        \n",
    "        #print report card\n",
    "        print(\"\\nReport Card:\\n----------------------------------------\\n\")\n",
    "        print(sep.show_report())\n",
    "        \n",
    "    \n",
    "    def predict(X):\n",
    "        \n",
    "        \"\"\"\n",
    "        Return predicted labels for exmaples X. \n",
    " \n",
    "        #### CURRENTLY THIS FUNCTION ISN'T USED - but could be called if we need predicted y vals \n",
    "        #### independently to the score function\n",
    " \n",
    "        \"\"\"\n",
    "        print(\"INside predict....\")\n",
    "        print(\"Thresh: \", self.threshold)\n",
    "        return (self.estimator.predict(X) > self.threshold).astype(int)\n",
    "        \n",
    "    def model_predict(self):\n",
    "        \"\"\"\n",
    "        Method to read in test data from file, make predictions\n",
    "        using trained model, and dump results to file \n",
    "        \n",
    "        #### CURRENTLY THIS FUNCTION ISN'T USED - leftover from FeatEngr homework but we might need to\n",
    "        #### to test on the holy grail test set\n",
    "        \"\"\"\n",
    "        \n",
    "        # read in test data \n",
    "        dfTest  = pd.read_csv(\"../data/spoilers/test.csv\")\n",
    "        \n",
    "        # featurize test data \n",
    "        self.X_test = self.get_test_features(list(dfTest[\"sentence\"]))\n",
    "        \n",
    "        # make predictions on test data \n",
    "        pred = self.estimator.predict(self.X_test)\n",
    "        \n",
    "        # dump predictions to file for submission to Kaggle  \n",
    "        #pd.DataFrame({\"spoiler\": np.array(pred, dtype=bool)}).to_csv(\"prediction.csv\", index=True, index_label=\"Id\")\n",
    "        \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data - for the gridsearcv the data needs to be loaded outside of the class\n",
    "dfTrain = pd.read_csv(\"AllEvtsShuffled_student_PB.csv\")          \n",
    "\n",
    "#create training and test set\n",
    "sep = SEPClass(LogisticRegression())\n",
    "\n",
    "#Turn off features that aren't fully fleshed out or don't work\n",
    "#sep.allmyfeatures.set_params(RawFeat=None)\n",
    "\n",
    "# get training features and labels \n",
    "X_total = sep.build_train_features(dfTrain)    #CHANGE\n",
    "y_total = np.array(dfTrain.sep, dtype=int)\n",
    "\n",
    "#split dataset into training and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_total,y_total,test_size=0.2,random_state=1230,stratify=y_total)\n",
    "\n",
    "#standardization\n",
    "#X_std = preprocessing.scale(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'gini'}\n",
      "{'learning_rate': 1.6000000000000005, 'n_estimators': 72}\n"
     ]
    }
   ],
   "source": [
    "''' DECISION TREES AND BOOSTING '''\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier as trees\n",
    "\n",
    "metric3 = make_scorer(matthews_corrcoef)\n",
    "\n",
    "def tss_score(y, y_pred):\n",
    "    tn, fp, fn, tp=confusion_matrix(y, y_pred).ravel()\n",
    "    tss = tp / (tp + fp + fn)\n",
    "    return tss\n",
    "\n",
    "def hss_score(y, y_pred):\n",
    "    tn, fp, fn, tp=confusion_matrix(y, y_pred).ravel()\n",
    "    E = ((tp + fn)*(tp + fp) + (fp + tn)*(fn + tn)) / X_train.shape[0]\n",
    "    HSS = (tp + tn - E)/(X_train.shape[0] - E)\n",
    "    return HSS\n",
    "\n",
    "metric5 = make_scorer(tss_score)\n",
    "metric6 = make_scorer(hss_score)\n",
    "\n",
    "dtc_keywords = {'max_depth':1, 'max_features':None,'random_state':1230,'min_samples_split':2,'min_samples_leaf':1}\n",
    "clf_keywords = {'random_state':1230}\n",
    "        \n",
    "dtc = trees(**dtc_keywords)\n",
    "clf = AdaBoostClassifier(dtc,**clf_keywords)\n",
    "\n",
    "dtc_params = {'criterion':['gini','entropy']}\n",
    "clf_params = {'n_estimators':range(50,92,2),'learning_rate':np.arange(1.6,0.1)}\n",
    "#50-100, 0.1-1\n",
    "\n",
    "dtc_search = GridSearchCV(dtc,dtc_params,scoring = metric5)\n",
    "dtc_search.fit(X_train,y_train)\n",
    "dtc_keywords.update(dtc_search.best_params_)\n",
    "print(dtc_search.best_params_)\n",
    "\n",
    "dtc_keywords.update(dtc_search.best_params_)\n",
    "dtc = trees(**dtc_keywords)\n",
    "clf = AdaBoostClassifier(dtc,**clf_keywords)\n",
    "\n",
    "clf_search = GridSearchCV(clf,clf_params, scoring = metric5)\n",
    "clf_search.fit(X_train,y_train)\n",
    "clf_keywords.update(clf_search.best_params_)\n",
    "print(clf_search.best_params_)\n",
    "\n",
    "#print(clf_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=1230,\n",
       "            splitter='best'),\n",
       "          learning_rate=1.6000000000000005, n_estimators=72,\n",
       "          random_state=1230)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train the model\n",
    "dtc = trees(**dtc_keywords)\n",
    "clf = AdaBoostClassifier(dtc,**clf_keywords)\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train the model\n",
    "#dtc = trees(max_depth = 1, max_features = None, random_state = 1230, min_samples_split = 2, min_samples_leaf = 1)\n",
    "#clf = AdaBoostClassifier(dtc,random_state = 1230,learning_rate = 0.25, n_estimators = 200 )\n",
    "#clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall \n",
      "\n",
      "[0.26315789 0.26315789 0.22222222 0.38888889 0.33333333 0.66666667] \n",
      "-------------------------\n",
      "\n",
      "precision \n",
      "\n",
      "[0.5        0.625      0.4        0.63636364 0.35294118 0.63157895] \n",
      "-------------------------\n",
      "\n",
      "matthews correlation coefficient \n",
      "\n",
      "[0.34618315 0.39225458 0.28013451 0.48409825 0.32044501 0.63612521] \n",
      "-------------------------\n",
      "\n",
      "brier score \n",
      "\n",
      "[0.03591682 0.03219697 0.03795066 0.028463   0.04364326 0.02466793] \n",
      "-------------------------\n",
      "\n",
      "true skill score \n",
      "\n",
      "[0.20833333 0.22727273 0.16666667 0.31818182 0.20689655 0.48      ] \n",
      "-------------------------\n",
      "\n",
      "Heidke Skill Score \n",
      "\n",
      "[0.13835339 0.13868217 0.13751659 0.13918236 0.13684729 0.14017754] \n",
      "-------------------------\n",
      "\n",
      "\n",
      "Training Set (no cross-validation) Score \n",
      "-----------------------------------\n",
      "\n",
      "recall \n",
      "\n",
      "0.4909090909090909 \n",
      "-------------------------\n",
      "\n",
      "precision \n",
      "\n",
      "0.782608695652174 \n",
      "-------------------------\n",
      "\n",
      "matthews correlation coefficient \n",
      "\n",
      "0.6095543010316704 \n",
      "-------------------------\n",
      "\n",
      "MSE: 0.0224\n",
      "BSL: 0.2293\n",
      "RefQuadScore: 0.0348\n",
      "\n",
      "SS: 0.3545\n",
      "FAR: 0.2174\n",
      "POD: 0.4909\n",
      "TSS: 0.4320\n",
      "HSS: 0.5924\n",
      "True Pos: 54, True Neg: 3040, False Pos: 15,. False Neg: 56\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      "-------------------------\n",
      "[[3040   15]\n",
      " [  56   54]]\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree Scores\n",
    "#cross validation\n",
    "folds = 6       \n",
    "    \n",
    "metric1 = 'recall'\n",
    "metric2 = 'precision'\n",
    "    \n",
    "metric3s = 'matthews correlation coefficient' \n",
    "metric3 = make_scorer(matthews_corrcoef)\n",
    "\n",
    "metric4s = \"brier score\" \n",
    "metric4 = make_scorer(brier_score_loss)\n",
    "\n",
    "metric5s = 'true skill score'\n",
    "\n",
    "metric6s = 'Heidke Skill Score'\n",
    "        \n",
    "        \n",
    "rec_score = cross_val_score(clf, X_train, y_train, cv=folds,scoring=metric1)\n",
    "prec_score = cross_val_score(clf, X_train, y_train, cv=folds,scoring=metric2)\n",
    "mattco_score = cross_val_score(clf, X_train, y_train, cv=folds,scoring=metric3)\n",
    "brier_score = cross_val_score(clf, X_train, y_train, cv=folds,scoring=metric4)\n",
    "tss_score = cross_val_score(clf, X_train, y_train, cv=folds,scoring=metric5)\n",
    "hss_score = cross_val_score(clf, X_train, y_train, cv=folds,scoring=metric6)\n",
    "\n",
    "print(metric1,'\\n')\n",
    "print(rec_score,'\\n-------------------------\\n')\n",
    "        \n",
    "print(metric2,'\\n')\n",
    "print(prec_score,'\\n-------------------------\\n')\n",
    "        \n",
    "print(metric3s,'\\n')\n",
    "print(mattco_score,'\\n-------------------------\\n')\n",
    "        \n",
    "print(metric4s,'\\n')\n",
    "print(brier_score,'\\n-------------------------\\n')\n",
    "\n",
    "print(metric5s,'\\n')\n",
    "print(tss_score,'\\n-------------------------\\n')\n",
    "\n",
    "print(metric6s,'\\n')\n",
    "print(hss_score,'\\n-------------------------\\n')\n",
    "\n",
    "#training set score (no cross-validation)\n",
    "y_train_pred = clf.predict(X_train)\n",
    "y_train_pred_prob = clf.predict_proba(X_train)\n",
    "print('\\nTraining Set (no cross-validation) Score \\n-----------------------------------\\n')\n",
    "        \n",
    "rec1_score = recall_score(y_train,y_train_pred)\n",
    "prec1_score = precision_score(y_train,y_train_pred)\n",
    "mattco1_score = matthews_corrcoef(y_train,y_train_pred)\n",
    "#tss1_score = tss_score(y_train,y_train_pred)\n",
    "        \n",
    "print(metric1,'\\n')\n",
    "print(rec1_score,'\\n-------------------------\\n')\n",
    "        \n",
    "print(metric2,'\\n')\n",
    "print(prec1_score,'\\n-------------------------\\n')\n",
    "        \n",
    "print(metric3s,'\\n')\n",
    "print(mattco1_score,'\\n-------------------------\\n')\n",
    "\n",
    "#print(metric5s,'\\n')\n",
    "#print(tss1_score,'\\n-------------------------\\n')\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"Method to show a report card of the model fit \"\"\"\n",
    "\n",
    "#calculate the mean square error\n",
    "mserr = mse(y_train, y_train_pred)\n",
    "print(\"MSE: %.4f\" % mserr)\n",
    "\n",
    "#calculate the Brier score - is this the same as the MSE? And QR referenced in Balch paper?\n",
    "bsloss = bsl(y_train, y_train_pred_prob[:,1])\n",
    "print(\"BSL: %.4f\" % bsloss)\n",
    "\n",
    "#Occurance rate = #SEPS / #events\n",
    "occ_rate = y_train.sum()/len(y_train)\n",
    "\n",
    "#Reference score of predicting all negative class\n",
    "#QR_star = 0.0324 Balch\n",
    "QR_star =  mse(y_train, np.zeros(len(y_train)))\n",
    "print(\"RefQuadScore: %.4f\\n\" % QR_star)\n",
    "\n",
    "#assume the QR is the same as the MSE - as stated later in Balch\n",
    "QR = mserr\n",
    "#QR = 0.0250 Balch​-\n",
    "\n",
    "#skill score \n",
    "SS = (QR_star - QR)/QR_star\n",
    "print(\"SS: %.4f\" % SS)\n",
    "\n",
    "tn, fp, fn, tp=confusion_matrix(y_train, y_train_pred).ravel()\n",
    "FAR = fp/(tp + fp)\n",
    "POD = tp/(tp + fn)\n",
    "TSS = tp / (tp+fp+fn)\n",
    "E = ((tp + fn)*(tp + fp) + (fp + tn)*(fn + tn)) / X_train.shape[0]\n",
    "HSS = (tp + tn - E)/(X_train.shape[0] - E)\n",
    "\n",
    "print(\"FAR: %.4f\" % FAR)\n",
    "print(\"POD: %.4f\" % POD)\n",
    "print(\"TSS: %.4f\" % TSS)\n",
    "print(\"HSS: %.4f\" % HSS)\n",
    "\n",
    "##ROC metrics\n",
    "fpr, tpr, thresh = roc_curve(y_train, y_train_pred, drop_intermediate=False)\n",
    "\n",
    "##Confusion Matrix\n",
    "\n",
    "print(\"True Pos: %i, True Neg: %i, False Pos: %i,. False Neg: %i\\n\" % (tp,tn,fp,fn))\n",
    "\n",
    "print(\"\\nConfusion Matrix\\n-------------------------\")\n",
    "conf_mat = confusion_matrix(y_train,y_train_pred) \n",
    "print(conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Set (no cross-validation) Score \n",
      "-----------------------------------\n",
      "\n",
      "recall \n",
      "\n",
      "0.39285714285714285 \n",
      "-------------------------\n",
      "\n",
      "precision \n",
      "\n",
      "0.4782608695652174 \n",
      "-------------------------\n",
      "\n",
      "matthews correlation coefficient \n",
      "\n",
      "0.41477551064581114 \n",
      "-------------------------\n",
      "\n",
      "MSE: 0.0366\n",
      "BSL: 0.2293\n",
      "RefQuadScore: 0.0354\n",
      "\n",
      "SS: -0.0357\n",
      "FAR: 0.5217\n",
      "POD: 0.3929\n",
      "TSS: 0.2750\n",
      "HSS: 0.1937\n",
      "True Pos: 11, True Neg: 752, False Pos: 12,. False Neg: 17\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      "-------------------------\n",
      "[[752  12]\n",
      " [ 17  11]]\n"
     ]
    }
   ],
   "source": [
    "#test set score (no cross-validation)\n",
    "y_test_pred = clf.predict(X_test)\n",
    "y_test_pred_prob = clf.predict_proba(X_test)\n",
    "print('\\nTraining Set (no cross-validation) Score \\n-----------------------------------\\n')\n",
    "        \n",
    "rec1_score = recall_score(y_test,y_test_pred)\n",
    "prec1_score = precision_score(y_test,y_test_pred)\n",
    "mattco1_score = matthews_corrcoef(y_test,y_test_pred)\n",
    "#tss1_score = tss_score(y_train,y_train_pred)\n",
    "        \n",
    "print(metric1,'\\n')\n",
    "print(rec1_score,'\\n-------------------------\\n')\n",
    "        \n",
    "print(metric2,'\\n')\n",
    "print(prec1_score,'\\n-------------------------\\n')\n",
    "        \n",
    "print(metric3s,'\\n')\n",
    "print(mattco1_score,'\\n-------------------------\\n')\n",
    "\n",
    "#print(metric5s,'\\n')\n",
    "#print(tss1_score,'\\n-------------------------\\n')\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"Method to show a report card of the model fit \"\"\"\n",
    "\n",
    "#calculate the mean square error\n",
    "mserr = mse(y_test, y_test_pred)\n",
    "print(\"MSE: %.4f\" % mserr)\n",
    "\n",
    "#calculate the Brier score - is this the same as the MSE? And QR referenced in Balch paper?\n",
    "bsloss = bsl(y_test, y_test_pred_prob[:,1])\n",
    "print(\"BSL: %.4f\" % bsloss)\n",
    "\n",
    "#Occurance rate = #SEPS / #events\n",
    "occ_rate = y_test.sum()/len(y_test)\n",
    "\n",
    "#Reference score of predicting all negative class\n",
    "#QR_star = 0.0324 Balch\n",
    "QR_star =  mse(y_test, np.zeros(len(y_test)))\n",
    "print(\"RefQuadScore: %.4f\\n\" % QR_star)\n",
    "\n",
    "#assume the QR is the same as the MSE - as stated later in Balch\n",
    "QR = mserr\n",
    "#QR = 0.0250 Balch​-\n",
    "\n",
    "#skill score \n",
    "SS = (QR_star - QR)/QR_star\n",
    "print(\"SS: %.4f\" % SS)\n",
    "\n",
    "tn, fp, fn, tp=confusion_matrix(y_test, y_test_pred).ravel()\n",
    "FAR = fp/(tp + fp)\n",
    "POD = tp/(tp + fn)\n",
    "TSS = tp / (tp+fp+fn)\n",
    "E = ((tp + fn)*(tp + fp) + (fp + tn)*(fn + tn)) / X_train.shape[0]\n",
    "HSS = (tp + tn - E)/(X_train.shape[0] - E)\n",
    "\n",
    "print(\"FAR: %.4f\" % FAR)\n",
    "print(\"POD: %.4f\" % POD)\n",
    "print(\"TSS: %.4f\" % TSS)\n",
    "print(\"HSS: %.4f\" % HSS)\n",
    "\n",
    "##ROC metrics\n",
    "fpr, tpr, thresh = roc_curve(y_test, y_test_pred, drop_intermediate=False)\n",
    "\n",
    "##Confusion Matrix\n",
    "\n",
    "print(\"True Pos: %i, True Neg: %i, False Pos: %i,. False Neg: %i\\n\" % (tp,tn,fp,fn))\n",
    "\n",
    "print(\"\\nConfusion Matrix\\n-------------------------\")\n",
    "conf_mat = confusion_matrix(y_test,y_test_pred) \n",
    "print(conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "#ROC\n",
    "fpr, tpr, thresholds = roc_curve(y_train,y_train_pred_prob[:,1],pos_label = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "threshold = 0.50\n",
    "temp = y_train_pred_prob[:,1] > threshold\n",
    "type(temp)\n",
    "temp.astype('int')\n",
    "temp2 = y_train + temp\n",
    "tp = len(np.where(temp2 == 2)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#fp,fn,tss\n",
    "fp = len(np.where(np.logical_and(temp == 1, y_train == 0))[0])\n",
    "fn = len(np.where(np.logical_and(temp == 0, y_train == 1))[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
