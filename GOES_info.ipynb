{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All this is old code from the first summer. See GOES_master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sunpy.instr.goes import get_goes_event_list\n",
    "from sunpy.time import parse_time, TimeRange, is_time_in_given_format\n",
    "t1_s = '2013/05/22 00:00'  \n",
    "t2_s = '2013/05/23 00:00'\n",
    "\n",
    "#query the goes event list for all flares before and after the flare peak time of the event you are interested in\n",
    "g_evt_list = get_goes_event_list(TimeRange(t1_s, t2_s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read 1 minute GOES data\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from sunpy.lightcurve import LightCurve\n",
    "from sunpy.instr.goes import calculate_temperature_em\n",
    "\n",
    "int_xs = [] #short xray\n",
    "int_xl = [] #long xray\n",
    "intflux_s = []\n",
    "intflux_l = []\n",
    "t_chianti = []\n",
    "em_chianti = []\n",
    "pkflux = []\n",
    "\n",
    "#for j in range(len(sep_new['Flare Max.'])):\n",
    "    #if isinstance(sep_new['Flare Max.'][j],str) and isinstance(start_time[j],datetime.date): #check for nan and correct dates\n",
    "        #flare_dat = sep_new['Flare Max.'][j]\n",
    "        year = '2015'\n",
    "        month = '10'\n",
    "\n",
    "        monthstart = '01'\n",
    "        leap_years = np.arange(1984,2020,4)\n",
    "        \n",
    "        #date for end of the month\n",
    "        days_31 = ['01','03','05','07','08','10','12']\n",
    "        days_30 = ['04','06','09','11']\n",
    "\n",
    "        if (month in days_31) == True:\n",
    "            monthend = '31'\n",
    "\n",
    "        elif (month in days_30) == True:\n",
    "            monthend = '30'\n",
    "\n",
    "        elif month == '02':\n",
    "            if (month in leap_years) == True:\n",
    "                monthend = '29'\n",
    "            else:\n",
    "                monthend = '28'\n",
    "        \n",
    "        #access url where goes data is kept\n",
    "        temp_url = \"https://satdat.ngdc.noaa.gov/sem/goes/data/avg/\"+year+\"/\"+month+'/'\n",
    "        res = requests.get(temp_url)\n",
    "        soup = BeautifulSoup(res.content,'lxml')\n",
    "        table = soup.find_all('table')\n",
    "        df = pd.read_html(str(table))[1]\n",
    "        goes_s =  list(df[0])[-1]\n",
    "        goes_num = goes_s[4:6]\n",
    "        path_to_csv = \"https://satdat.ngdc.noaa.gov/sem/goes/data/avg/\"+year+\"/\"+month+'/'+goes_s+\"csv/g\"+goes_num+\"_xrs_1m_\"+year+month+monthstart+\"_\"+year+month+monthend+\".csv\"\n",
    "\n",
    "        url = path_to_csv\n",
    "\n",
    "        import urllib\n",
    "        try: response = urllib.request.urlopen(url)\n",
    "        except: url = \"https://satdat.ngdc.noaa.gov/sem/goes/data/avg/\"+year+\"/\"+month+'/'+list(df[0])[-2]+\"csv/g\"+list(df[0])[-2][4:6]+\"_xrs_1m_\"+year+month+monthstart+\"_\"+year+month+monthend+\".csv\"\n",
    "        response = urllib.request.urlopen(url)\n",
    "            \n",
    "        data = response.read().decode('utf-8')\n",
    "\n",
    "        datasplit = data.split('\\n')\n",
    "        \n",
    "        #put data in readable format and looks for line where xray data begins\n",
    "        for rownum, row in enumerate(datasplit):\n",
    "            if row[0:8] == \"time_tag\":\n",
    "                nskiprows = rownum + 1\n",
    "        \n",
    "        #parsing function\n",
    "        parser = lambda x: pd.datetime.strptime(x, \"%Y-%m-%d %H:%M:%S.%f\")          \n",
    "\n",
    "        #read in cvs file from url and parse column time_tag with the function parse\n",
    "        if url[59:61] == '12':\n",
    "            c = pd.read_csv(url, skiprows=nskiprows, parse_dates=['time_tag'] ,date_parser = parser,names = ['time_tag','xs','xl'])\n",
    "        else:\n",
    "            c = pd.read_csv(url, skiprows=nskiprows, parse_dates=['time_tag'] ,date_parser = parser,names = ['time_tag','xs','xl'],usecols = [0,3,6])\n",
    "    \n",
    "        #set time_tag to the index\n",
    "        c.set_index('time_tag',inplace=True)  \n",
    "\n",
    "        #find just the subset of dates between the flare start time and end time - has to be a date time format\n",
    "        t1_s = datetime.datetime.strftime(start_time[j], '%Y/%m/%d %H:%M')  \n",
    "        t2_s = datetime.datetime.strftime(end_time[j], '%Y/%m/%d %H:%M')\n",
    "        data_subset = c[t1_s:t2_s]  \n",
    "\n",
    "        #sum over the time - 60 second time intervals\n",
    "        sum_xrsa = (60 * data_subset['xs']).sum()\n",
    "        sum_xrsb = (60 * data_subset['xl']).sum()\n",
    "        \n",
    "        int_xs.append(sum_xrsa)\n",
    "        int_xl.append(sum_xrsb)\n",
    "        \n",
    "        #integrated flux with background radiation subtracted\n",
    "        flx_s = (60 * (data_subset['xs'] - data_subset['xs'][0])).sum()\n",
    "        flx_l = (60 * (data_subset['xl'] - data_subset['xl'][0])).sum()\n",
    "        \n",
    "        intflux_s.append(flx_s)\n",
    "        intflux_l.append(flx_l)\n",
    "        \n",
    "        ###temperature and emission measures\n",
    "        #convert the 1 min GOES data into a GOES lightcurve object - required for temp and em calculation\n",
    "        lc = LightCurve.create({\"xrsa\": data_subset['xs'], \"xrsb\":data_subset['xl']}, index = data_subset.index)\n",
    "\n",
    "        #add the satellite id to the meta data of the lightcurve object i.e. GOES 10, GOES 11, GOES 12\n",
    "        name1 = goes_s\n",
    "        name2 = name1.upper().split('S')\n",
    "        name3 = name2[0] + 'S ' + name2[1][0:2]\n",
    "        lc.meta[\"TELESCOP\"] = name3\n",
    "\n",
    "        #if an error arises and the temp is not in the accpetable range check to see if there are any \n",
    "        #negative values equal to -9999.0 in the array. keep only the rows that don't have an exray \n",
    "        #flux of -99999 (or whatever value they use that marks a bad value)\n",
    "        lc.data.xrsa = lc.data.xrsa[lc.data.xrsa != -99999.0]\n",
    "        lc.data.xrsb = lc.data.xrsb[lc.data.xrsb != -99999.0]\n",
    "\n",
    "        #calculate the temperature and emission measure\n",
    "        lc_new = calculate_temperature_em(lc) \n",
    "\n",
    "        #flare max temp and em\n",
    "        temp = lc_new.data.temperature.max()\n",
    "        em = lc_new.data.em.max()\n",
    "        \n",
    "        t_chianti.append(temp)\n",
    "        em_chianti.append(em)\n",
    "        \n",
    "        #flare peak flux \n",
    "        flrpk = data_subset['xl'].max()\n",
    "        pkflux.append(flrpk)\n",
    "        \n",
    "    else:\n",
    "        int_xs.append(nan)\n",
    "        int_xl.append(nan)\n",
    "        intflux_s.append(nan)\n",
    "        intflux_l.append(nan)\n",
    "        t_chianti.append(nan)\n",
    "        em_chianti.append(nan)\n",
    "        pkflux.append(nan)\n",
    "        \n",
    "  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
